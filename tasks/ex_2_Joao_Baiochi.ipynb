{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SCC-ICMC-USP - 1o. semestre de 2024\n",
    "\n",
    "## SCC5871/MAI5025 - Exercício 2\n",
    "\n",
    "## Profa. Roseli A. F. Romero\n",
    "\n",
    "\n",
    "Nro do grupo: - \n",
    "\n",
    "Alunos:\n",
    "\n",
    "1.   João Francisco Baiochi (n.ºUSP 7547674)\n",
    "2.   \n",
    "  \n",
    "Notebook source: [GitHub](https://github.com/baiochi/SCC5871_Ver6_Turma3_2024)\n",
    "\n",
    "---  \n",
    "\n",
    "Para esse exercício, vamos utilizar o dataset Iris. Ele descreve atributos sobre 3 tipos de flores.\n",
    "O objetivo é classificar qual o tipo de flor conforme os atributos disponíveis. Vamos trabalhar apenas com as duas primeiras classes para que\n",
    "o problema de classificação binária."
   ],
   "metadata": {
    "id": "IYJjTJn6VO9q"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Ignore ConvergenceWarning\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "\n",
    "iris = load_iris()\n",
    "# Nessa primeira parte, vamos trabalhar apenas com as duas primeiras features e as duas primeiras classes\n",
    "X = iris.data[:100, :4]\n",
    "y = iris.target[:100]"
   ],
   "metadata": {
    "id": "RCkrc7OCYsxn",
    "ExecuteTime": {
     "end_time": "2024-05-18T02:07:58.771572Z",
     "start_time": "2024-05-18T02:07:56.106910Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "### Questão 1.\n",
    "\n",
    "\n",
    "- a) Utilizando o sklearn, defina uma [MLP para classificação binária](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) com a seguinte configuração:\n",
    "    - função de ativação ReLU;\n",
    "    - duas camadas escondidads com 10 neurônios cada;\n",
    "    - taxa de aprendizado igual a 1e-2;\n",
    "    - utilizando o algoritmo de otimização de gradiente descendente estocástico;\n",
    "    - utilizando 10 iterações máximas (épocas);\n",
    "    - use random_state=1234\n",
    "\n",
    "\n",
    "- b) Treine a MLP definida no conjunto Iris simplificado definido na questçao anterior, e calcule a cross-entropy loss binária seguindo a definição a seguir."
   ],
   "metadata": {
    "id": "kBtKuWdgWJ3W"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T02:07:58.913571Z",
     "start_time": "2024-05-18T02:07:58.774571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Configurando a instância MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 10),\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=1e-2,\n",
    "                    solver='sgd',\n",
    "                    max_iter=10,\n",
    "                    random_state=1234)\n",
    "\n",
    "# Treinando o modelo\n",
    "mlp.fit(X, y)\n",
    "\n",
    "# Fazendo as predições\n",
    "y_pred = mlp.predict_proba(X)\n",
    "\n",
    "# Cálculo da cross-entropy loss\n",
    "loss = log_loss(y, y_pred)\n",
    "\n",
    "print(f'Cross-entropy loss: {loss}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-entropy loss: 0.43160839201457435\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "### Questão 2.\n",
    "\n",
    "Para avaliar os modelos que serão testados, implemente a função `evaluate_model()`. Essa função recebe um modelo de classificador genérico (`model`) e avalia sua acurácia utilizando **10-fold stratified cross-validation**, retornando a média das acurácias de cada fold. O parâmetro `X` indica os dados e `y` os labels.\n",
    "- Sugestão: há duas formas de implementar a validação cruzada: treinar manualmente os modelos nos [splits gerados](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) ou utilizar a função [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) do sklearn. Atente-se ao cálculo da acurácia.\n",
    "\n",
    "- Para garantir uma melhor performance dos algoritmos, faça o preprocessamento desses dados através da classe `sklearn.preprocessing.StandardScaler`."
   ],
   "metadata": {
    "id": "7GQGz90SWaqd"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T02:07:59.056575Z",
     "start_time": "2024-05-18T02:07:58.916574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    scores = cross_val_score(model, X, y,\n",
    "                             cv=StratifiedKFold(n_splits=10),\n",
    "                             scoring='accuracy')\n",
    "    # print(scores)\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# Aplicando o preprocessamento dos dados\n",
    "scaler = StandardScaler()\n",
    "X_transf = scaler.fit_transform(X)\n",
    "\n",
    "# Testando a função\n",
    "print(f'Acurácia média: {evaluate_model(mlp, X_transf, y) * 100:.2f}%')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 50.00%\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "### Questão 3.\n",
    "\n",
    "Agora para estruturar e organizar melhor nossos testes, vamos utilizar as estruturas de dicionário do Python. Por exemplo, se formos definir dois modelos de Multi-Layer Perceptron, podemos escrever:\n",
    "\n",
    "```\n",
    "experimentos = {\n",
    "    \"MLP camada escondida (5,)\": MLPClassifier(hidden_layer_sizes=(5,),\n",
    "    \"MLP camada escondida (5,5)\": MLPClassifier(hidden_layer_sizes=(5,5)        \n",
    "}\n",
    "```\n",
    "\n",
    "Isso pode ser feito pois o Python trata funções como funções de primeira classe. Isso é, funções podem ser tratadas como variáveis.\n",
    "\n",
    "Portanto, defina um dicionário de experimentos com ao menos 3 modelos de MLP (`sklearn.neural_network.MLPClassifier`). Para isso varie parâmetros como o número de camadas escondidas, função de ativação e número de neurônios.\n",
    "\n",
    "- Dica: Ver documentação em https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "- Utilize um número de iterações >= 50 para garantir convergência.\n",
    "- Experimente diferentes taxas de aprendizado e número máximo de iterações (épocas) de forma a garantir convergência no treino."
   ],
   "metadata": {
    "id": "0OAqBPC9W7Ul"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T02:07:59.072574Z",
     "start_time": "2024-05-18T02:07:59.060576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "experimentos = {\n",
    "    \"MLP camada escondida (5,)\": MLPClassifier(hidden_layer_sizes=(5,),\n",
    "                                               activation='relu',\n",
    "                                               learning_rate_init=1e-3,\n",
    "                                               solver='sgd',\n",
    "                                               max_iter=50,\n",
    "                                               random_state=1234),\n",
    "    \"MLP camada escondida (10,5)\": MLPClassifier(hidden_layer_sizes=(10, 5),\n",
    "                                                 activation='logistic',\n",
    "                                                 learning_rate_init=1e-2,\n",
    "                                                 solver='lbfgs',\n",
    "                                                 max_iter=100,\n",
    "                                                 random_state=1234),\n",
    "    \"MLP camada escondida (15,10,5)\": MLPClassifier(hidden_layer_sizes=(15, 10, 5),\n",
    "                                                     activation='relu',\n",
    "                                                     learning_rate_init=1e-5,\n",
    "                                                     solver='sgd',\n",
    "                                                     max_iter=150,\n",
    "                                                     random_state=1234),\n",
    "    \"MLP camada escondida (20,15,10,5)\": MLPClassifier(hidden_layer_sizes=(20, 15, 10, 5),\n",
    "                                                        activation='relu',\n",
    "                                                        learning_rate_init=1e-5,\n",
    "                                                        solver='lbfgs',\n",
    "                                                        max_iter=100,\n",
    "                                                        random_state=1234)\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "### Questão 4.\n",
    "\n",
    "- a) Para cada modelo instanciado na Questão 3, utilize a função criada na questão 3 para calcular sua acurácia. Exiba o nome do modelo e sua acurácia.\n",
    "- b) Determine qual o melhor classificador dentre os especificados e justifique sua escolha."
   ],
   "metadata": {
    "id": "WF4OInsQXaGJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = iris.data.copy()\n",
    "y = iris.target.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "# Avaliando os modelos\n",
    "for model_name, model in experimentos.items():\n",
    "    acc = evaluate_model(model, X_train, y_train)\n",
    "    print(f'{model_name}: acurácia = {acc * 100:.2f}%')"
   ],
   "metadata": {
    "id": "uXJF7LngVkjC",
    "ExecuteTime": {
     "end_time": "2024-05-18T02:08:04.148595Z",
     "start_time": "2024-05-18T02:07:59.075575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP camada escondida (5,): acurácia = 31.67%\n",
      "MLP camada escondida (10,5): acurácia = 96.67%\n",
      "MLP camada escondida (15,10,5): acurácia = 30.83%\n",
      "MLP camada escondida (20,15,10,5): acurácia = 95.00%\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "O modelo com melhor desempenho foi o \"MLP camada escondida (10,5)\" com acurácia de 96.67%. Um diferencial foi a utilização do `solver='lbfgs'` que é um otimizador de segunda ordem, adequado para conjunto de dados pequenos. Aumentar o número de camadas e quantidades de neurônios não teve um grande impacto, visto que o último modelo possuiu mais parâmetros e obteve uma acurácia menor.  \n",
    "Por fim precisamos fazer a comparação da acurácia entre os dados de treino e teste para verificar se o modelo está sofrendo de overfitting."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T02:08:04.259595Z",
     "start_time": "2024-05-18T02:08:04.150576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mlp = experimentos['MLP camada escondida (10,5)']\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Train accuracy\n",
    "y_pred = mlp.predict(X_train)\n",
    "acc = np.mean(y_pred == y_train)\n",
    "print(f'Train accuracy: {acc * 100:.2f}%')\n",
    "\n",
    "# Test accuracy\n",
    "y_pred = mlp.predict(X_test)\n",
    "acc = np.mean(y_pred == y_test)\n",
    "print(f'Test accuracy: {acc * 100:.2f}%')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 99.17%\n",
      "Test accuracy: 100.00%\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Verificamos que o modelo obteve valores muito próximos de acurácia para os dados de treino e teste, indicando que não está sofrendo de overfitting e soube generalizar para dados não vistos anteriormente."
  }
 ]
}
