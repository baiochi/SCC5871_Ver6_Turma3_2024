{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# SCC-ICMC-USP - 1o. semestre de 2024\n",
    "\n",
    "## SCC5871/MAI5025 - Exercício 1\n",
    "\n",
    "## Profa. Roseli A. F. Romero\n",
    "\n",
    "\n",
    "Nro do grupo: - \n",
    "\n",
    "Alunos:\n",
    "\n",
    "1.   João Francisco Baiochi (n.ºUSP 7547674)\n",
    "2.   \n",
    "\n",
    "---  \n",
    "\n",
    "## Instruções  \n",
    "  \n",
    "A partir da base de dados do Kaggle, ```abalone.dat```, aplicar os 3 tipos de regressão:\n",
    "\n",
    "- Regressão Linear\n",
    "- Regressão Polinomial de grau 2\n",
    "- regressão Lasso\n",
    "- regressão RIDGE\n",
    "  \n",
    "Comparar as três métricas: MSE, MAE e R2 para cada tipo de regressão.\n",
    "\n",
    "Dataset source: [Kaggle](https://www.kaggle.com/datasets/rodolfomendes/abalone-dataset)  \n",
    "Notebook source: [GitHub](https://github.com/baiochi/SCC5871_Ver6_Turma3_2024)"
   ],
   "id": "49f9677038db4cda"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Table of contents\n",
    "\n",
    "1. [Exploratory Data Analysis](#exploratory-data-analysis)\n",
    "   1. [Numerical features](#numerical-features)\n",
    "   2. [Categorical features](#categorical-features)\n",
    "   3. [Target](#target-feature)\n",
    "2. [Modeling](#modeling)\n",
    "   1. [Linear Regression](#linear-regression)\n",
    "   2. [Polynomial Regression](#polynomial-regression)\n",
    "   3. [Lasso regularization](#lasso-regularization)\n",
    "   4. [RIDGE regularization](#ridge-regularization)\n",
    "   5. [Optimizing the model](#optimizing-the-model)\n",
    "3. [Conclusions](#conclusions)\n"
   ],
   "id": "fbc4855b0a7b147b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-11T02:13:17.805127Z",
     "start_time": "2024-05-11T02:13:13.351064Z"
    }
   },
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import session_info\n",
    "from src.utils import (numerical_plot, categorical_plot, plot_heatmap,\n",
    "                       get_metrics, get_feature_importance,\n",
    "                       plot_regression_results, metrics_report)\n",
    "\n",
    "# Supress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set grid style\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "session_info.show(excludes=['src'], dependencies=False)"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Análise Exploratória dos Dados",
   "id": "5295095a7aa5c025"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T02:13:17.901151Z",
     "start_time": "2024-05-11T02:13:17.809121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load Abalon dataset\n",
    "df = pd.read_csv('../data/abalone.csv')\n",
    "df.info()\n",
    "display(df.head())"
   ],
   "id": "519d87de46a74e10",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T02:13:17.917147Z",
     "start_time": "2024-05-11T02:13:17.904149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define target and features\n",
    "target = 'Rings'\n",
    "features = df.drop(columns=target).columns.tolist()"
   ],
   "id": "23c51817c125597c",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.1. Features numéricas",
   "id": "c3676b6a9897c690"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T02:13:27.088273Z",
     "start_time": "2024-05-11T02:13:17.923151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for col in df.select_dtypes(include='float64').columns:\n",
    "    numerical_plot(df, col, target)"
   ],
   "id": "43b7cb0486632f7c",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.2. Features categóricas",
   "id": "2bcfbcdbae7f14de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T02:13:27.681496Z",
     "start_time": "2024-05-11T02:13:27.090888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for col in df.select_dtypes(include='object').columns:\n",
    "    categorical_plot(df, col, target)"
   ],
   "id": "bdeaca4e8bd10fe5",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.3. Distribuição do target",
   "id": "37c8bb305205bc07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T02:13:28.364334Z",
     "start_time": "2024-05-11T02:13:27.684548Z"
    }
   },
   "cell_type": "code",
   "source": "numerical_plot(df, target)",
   "id": "9adab02a3f3ec722",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T02:13:29.079624Z",
     "start_time": "2024-05-11T02:13:28.367333Z"
    }
   },
   "cell_type": "code",
   "source": "plot_heatmap(df, target)",
   "id": "1ce23d229535af92",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Modelagem",
   "id": "a85aa173a2e497e1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Nesta seção da modelagem, vamos preparando os dados para o treinamento do modelo. As seguintes etapas serão realizadas:\n",
    "\n",
    "1. Definição do alvo e das características: primeiro, definimos a variável alvo (y) e as features (X). A variável alvo é o que queremos prever, enquanto as características são os dados que usaremos para fazer essa previsão.  \n",
    "\n",
    "2. Divisão dos dados: Em seguida, dividimos nossos dados em conjuntos de treinamento e teste usando a função ``train_test_split`` do sklearn. Isso nos permite treinar nosso modelo em um conjunto de dados e depois testá-lo em um conjunto de dados separado que o modelo nunca viu antes. Neste caso, estamos usando 80% dos dados para treinamento e 20% para teste.  \n",
    "3. Construção do pipeline de pré-processamento: aqui, estamos construindo um pipeline de pré-processamento para preparar nossos dados para o modelo. Este pipeline trata separadamente das características numéricas e categóricas:  \n",
    "    - Para as características numéricas, estamos aplicando um ``StandardScaler``, que padroniza as características subtraindo a média e, em seguida, escalonando para a unidade de variância.  \n",
    "    - Para as características categóricas, estamos aplicando um ``OneHotEncoder``, que converte variáveis categóricas em uma forma que pode ser fornecida aos algoritmos de Machine Learning.  \n",
    "\n",
    "Para avaliar o desempenho de cada modelo, vamos analisar as seguintes métricas de avaliação:\n",
    "- **MAE**: mais simples de entender, mas ela penaliza mais erros menores;\n",
    "- **MSE**: mais comum, pois essa métrica penaliza mais os erros maiores, o que faz mais sentido em aplicações reais.\n",
    "- **RMSE**: mais popular, pois esta métrica está nas mesmas unidades que o target.\n",
    "- **R2**: tem variação de 0 a 1, onde 1 é o melhor valor. Ela é uma métrica que mede a proporção da variância do target explicada pelo modelo.  "
   ],
   "id": "820929d387085a5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T02:13:29.191618Z",
     "start_time": "2024-05-11T02:13:29.148623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Define target and features\n",
    "X = df.drop(columns=target).copy()\n",
    "y = df[target].copy()\n",
    "\n",
    "test_size = .2\n",
    "random_state = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=test_size,\n",
    "    random_state=random_state)\n",
    "\n",
    "# Build Preprocessing pipeline\n",
    "numerical_features = X.select_dtypes(include='float64').columns\n",
    "categorical_features = X.select_dtypes(include='object').columns\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('numerical', numerical_pipeline, numerical_features),\n",
    "    ('categorical', categorical_pipeline, categorical_features)\n",
    "])"
   ],
   "id": "5ab63eb109b268e8",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1. Regressão Linear",
   "id": "92da5653b02eaff3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T02:13:31.972194Z",
     "start_time": "2024-05-11T02:13:29.193619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Model Pipeline\n",
    "lr_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Display metrics\n",
    "lr_metrics = get_metrics(lr_model, X, y, cv=True)\n",
    "print('Linear Regression metrics:')\n",
    "display(lr_metrics)\n",
    "lr_feature_importance = get_feature_importance(lr_model)\n",
    "plot_regression_results(y_test, y_pred,\n",
    "                        lr_metrics.loc[['R2_CV', 'RMSE_CV'], 'Test'].values,\n",
    "                        lr_feature_importance)"
   ],
   "id": "81693d3f453c3cb7",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Este modelo serve como nossa base para comparar e avaliar o desempenho de modelos mais sofisticados. A Regressão Linear, sendo um modelo simples, pressupõe uma relação linear entre as características (features) e a variável alvo (target). No entanto, observamos que, além de apresentar um score relativamente baixo, a distribuição dos resíduos não é uniforme. Isso sugere que o modelo não está sendo eficaz em capturar a relação existente entre as características e a variável alvo.",
   "id": "6ef281ebf41424ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2. Regressão Polinomial",
   "id": "3d1b0e48772ce9eb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Em seguida, usaremos a classe `PolynomialFeatures` para criar novas características que são combinações polinomiais das características existentes. Este método aumenta a complexidade do modelo, possibilitando a captura de relações não lineares entre as características e a variável alvo.  \n",
    "\n",
    "No entanto, é crucial lembrar que a adição de inúmeros características polinomiais pode resultar em overfitting. Isso ocorre quando o modelo se torna excessivamente complexo e começa a capturar o ruído presente nos dados de treinamento, em vez de aprender a verdadeira relação subjacente. Para evitar isso, é recomendável utilizar a validação cruzada para determinar o grau polinomial que proporciona o melhor desempenho do modelo, equilibrando a complexidade e a capacidade de generalização."
   ],
   "id": "9ef232fc4d815a24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T02:13:52.892176Z",
     "start_time": "2024-05-11T02:13:31.979196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_metrics = {}\n",
    "for degree in [2, 3, 4]:\n",
    "    poly_model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('poly', PolynomialFeatures(degree=degree)),\n",
    "        ('model', LinearRegression())\n",
    "    ])\n",
    "    \n",
    "    # Fit model\n",
    "    poly_model.fit(X_train, y_train)\n",
    "    _metrics = get_metrics(poly_model, X, y, cv=True)\n",
    "    poly_metrics[degree] = {\n",
    "        'R2': _metrics.loc['R2_CV', 'Test'],\n",
    "        'RMSE': _metrics.loc['RMSE_CV', 'Test']\n",
    "    }\n",
    "    \n",
    "print('Polynomial Regression metrics:')\n",
    "for degree, metrics in poly_metrics.items():\n",
    "    print(f'Degree {degree}: R2={metrics[\"R2\"]:.2f}, RMSE={metrics[\"RMSE\"]:.2f}')\n",
    "    \n",
    "\n",
    "# Run best model\n",
    "best_degree = max(poly_metrics, key=lambda x: poly_metrics[x]['R2'])\n",
    "poly_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly', PolynomialFeatures(degree=best_degree)),\n",
    "    ('model', LinearRegression())\n",
    "]).fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = poly_model.predict(X_test)\n",
    "\n",
    "# Display metrics\n",
    "poly_metrics = get_metrics(poly_model, X, y, cv=True)\n",
    "print(f'Best Polynomial Regression metrics (degree={best_degree}):')\n",
    "display(poly_metrics)\n",
    "poly_feature_importance = get_feature_importance(poly_model)\n",
    "plot_regression_results(y_test, y_pred,\n",
    "                        poly_metrics.loc[['R2_CV', 'RMSE_CV'], 'Test'].values,\n",
    "                        poly_feature_importance,\n",
    "                        order=best_degree)"
   ],
   "id": "25d88b61d32a7a39",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As métricas revelam que, dentre os modelos de regressão polinomial testados, o de segundo grau apresentou um desempenho superior aos de terceiro e quarto graus. No entanto, mesmo o modelo de segundo grau não conseguiu superar o desempenho do modelo de regressão linear anteriormente aplicado. Tanto o coeficiente de determinação (R2), quanto o erro quadrático médio da raiz (RMSE), embora maior do que para os outros graus polinomiais, ainda é inferior ao obtido pelo modelo linear. \n",
    "  \n",
    "Para os modelos de terceiro e quarto graus, as métricas indicam um desempenho ainda mais insatisfatório. O R2 negativo para os graus 3 e 4 sugere que esses modelos se ajustaram menos eficientemente aos dados do que um modelo horizontal simples. Ademais, o RMSE elevado para o grau 4 revela que as previsões deste modelo divergem significativamente dos valores reais.   \n",
    "\n",
    "Esses resultados indicam que a inclusão de características polinomiais de grau superior não aprimorou o desempenho do modelo. Também podemos descartar a ocorrência de overfitting, uma situação em que o modelo se torna excessivamente complexo e começa a capturar o ruído nos dados, pois as métricas de treino e teste apresentaram valores muito próximos."
   ],
   "id": "3d7fd645ad708667"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.3. Lasso (L1)",
   "id": "2efbab7d7464ca6f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "A regularização Lasso (Least Absolute Shrinkage and Selection Operator) é uma técnica de regularização usada em modelos de aprendizado de máquina e estatística para prevenir o overfitting e melhorar a interpretabilidade do modelo.   \n",
    "\n",
    "A regularização Lasso adiciona uma penalidade ao termo de erro do modelo que é proporcional ao valor absoluto dos coeficientes do modelo. Esta penalidade tem o efeito de encolher alguns dos coeficientes para zero, o que é equivalente a eliminar a característica correspondente do modelo. Isso pode ser útil quando você tem inúmeras características e acredita que apenas algumas delas são realmente importantes.   \n",
    "\n",
    "A força da penalidade Lasso é controlada por um hiperparâmetro, geralmente denotado por λ (lambda). Quando λ é zero, a regularização Lasso é equivalente a uma regressão linear comum. À medida que λ aumenta, a penalidade de regularização se fortalece e mais coeficientes são encolhidos para zero. Se λ for muito grande, todos os coeficientes podem ser encolhidos para zero, resultando em um modelo que é muito simples e subajustado."
   ],
   "id": "2310d76cfd1fbcb0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T02:13:55.335100Z",
     "start_time": "2024-05-11T02:13:52.895296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Model Pipeline\n",
    "lasso_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', Lasso())\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = lasso_model.predict(X_test)\n",
    "\n",
    "# Display metrics\n",
    "lasso_metrics = get_metrics(lasso_model, X, y, cv=True)\n",
    "lasso_feature_importance = get_feature_importance(lasso_model)\n",
    "print('Lasso Regression metrics:')\n",
    "display(lasso_metrics)\n",
    "plot_regression_results(y_test, y_pred,\n",
    "                        lasso_metrics.loc[['R2_CV', 'RMSE_CV'], 'Test'].values,\n",
    "                        lasso_feature_importance)"
   ],
   "id": "eda4dde33a6e6dc0",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Os resultados indicam que o modelo Lasso não teve um bom desempenho. O coeficiente de determinação (R2) para os dados de treinamento e teste foi de aproximadamente 0,29, o que indica que o modelo só conseguiu explicar cerca de 29% da variância na variável dependente. Além disso, o valor de R2 para a validação cruzada (R2_CV) foi de apenas 0.157, sendo o pior modelo até o momento.\n",
    "\n",
    "Esses resultados podem ser devido à natureza da regularização Lasso, que tende a encolher alguns dos coeficientes do modelo para zero. Isso pode resultar na eliminação de algumas características de fato importantes para a previsão da variável dependente. Este comportamento é evidenciado pela importância das features, onde muitas delas foram zeradas, sobrando apenas a feature `Shell weight` com coeficiente não nulo."
   ],
   "id": "1ef758b4c2fbeeb7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.4. RIDGE (L2)",
   "id": "f01bb0f8d5dc6ab3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "A principal diferença entre a regularização Lasso e Ridge é que a Ridge não encolhe os coeficientes para zero. Em vez disso, ela os reduz para valores muito pequenos. Isso significa que, enquanto a regularização Lasso pode eliminar características completamente, a regularização Ridge mantém todas as características, mas reduz a magnitude dos coeficientes para as características menos importantes.  ",
   "id": "58a44b7d7d573cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T02:13:57.892822Z",
     "start_time": "2024-05-11T02:13:55.338100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Model Pipeline\n",
    "ridge_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', Ridge(alpha=10))\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = ridge_model.predict(X_test)\n",
    "\n",
    "# Display metrics\n",
    "ridge_metrics = get_metrics(ridge_model, X, y, cv=True)\n",
    "print('Ridge Regression metrics:')\n",
    "display(ridge_metrics)\n",
    "ridge_feature_importance = get_feature_importance(ridge_model)\n",
    "plot_regression_results(y_test, y_pred,\n",
    "                        ridge_metrics.loc[['R2_CV', 'RMSE_CV'], 'Test'].values,\n",
    "                        ridge_feature_importance)"
   ],
   "id": "5d4a823150b34309",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "A aplicação da regularização RIDGE resultou no melhor modelo até o momento, entretando ainda está bem próximo ao modelo baseline de regressão linear. Com esse resultado, podemos concluir que a regularização L2 foi mais eficaz do que a regularização L1 para este conjunto de dados e, aplicar feature selection não beneficia o modelo.",
   "id": "6974acb23a2e25f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.5. Otimizando o modelo",
   "id": "e332e7889beac77c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "O próximo passo em nossa análise é buscar um modelo ainda mais eficaz. Para isso, vamos explorar a escolha do melhor grau para a regressão polinomial e os melhores parâmetros de regularização. A estratégia será utilizar a técnica de busca randomizada de hiper-parâmetros, conhecida como ```GridSearchCV```. Essa técnica permite uma exploração eficiente do espaço de hiper-parâmetros, o que pode nos levar a um modelo de regressão polinomial com desempenho superior e parâmetros de regularização mais adequados para nossos dados.  \n",
    "Também será utilizado o modelo ```ElasticNet```, que combina as regularizações L1 e L2, e com o hiper-parâmetro ```l1_ratio``` variando de 0 a 1, podemos explorar diferentes combinações de regularizações."
   ],
   "id": "673dfd08d4e38ff3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T02:16:35.191361Z",
     "start_time": "2024-05-11T02:13:57.895825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Define grid of hyperparameters\n",
    "param_grid = {\n",
    "    'poly__degree': [2, 3, 4],\n",
    "    'model__alpha': [0.1, 0.5, 1, 5, 10],\n",
    "    'model__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "# Model Pipeline\n",
    "elastic_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly', PolynomialFeatures()),\n",
    "    ('model', ElasticNet())\n",
    "])\n",
    "\n",
    "# Grid Search\n",
    "elastic_search = GridSearchCV(\n",
    "    elastic_model,\n",
    "    param_grid,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "elastic_search.fit(X_train, y_train)\n",
    "best_model = elastic_search.best_estimator_\n",
    "best_params = elastic_search.best_params_\n",
    "print('Best parameters:', best_params)\n",
    "\n",
    "elastic_search"
   ],
   "id": "351650b328d6eae8",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T02:16:36.772361Z",
     "start_time": "2024-05-11T02:16:35.194359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Predict\n",
    "y_pred = elastic_search.predict(X_test)\n",
    "\n",
    "# Display metrics\n",
    "best_metrics = get_metrics(best_model, X, y, cv=False)  # CV already done in GridSearch\n",
    "best_feature_importance = get_feature_importance(best_model)\n",
    "plot_regression_results(y_test, y_pred,\n",
    "                        best_metrics.loc[['R2', 'RMSE'], 'Test'].values,\n",
    "                        best_feature_importance.nlargest(10),\n",
    "                        order=best_params['poly__degree'])"
   ],
   "id": "56b13a8dcd27c423",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Conclusões",
   "id": "cba70195fb0e0cc2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T02:29:40.466559Z",
     "start_time": "2024-05-11T02:29:38.472562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics_report(\n",
    "    model_metrics=[lr_metrics, poly_metrics, lasso_metrics, ridge_metrics, \n",
    "                   best_metrics.rename({'RMSE': 'RMSE_CV','R2': 'R2_CV'})],\n",
    "    model_names=['Linear', 'Polynomial', 'Lasso', 'Ridge', 'ElasticNet'],\n",
    "    plot_metrics=['RMSE_CV', 'R2_CV'],\n",
    "    fig_width=14, fig_height=6\n",
    ")"
   ],
   "id": "62631a6fc479cbfc",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Em todos os modelos de regressão avaliados, a ocorrência de overfitting foi efetivamente descartada. Esta conclusão é suportada pela proximidade dos valores das métricas de treino e teste, indicando uma boa generalização dos modelos para dados não vistos durante o treinamento. Assim, o desempenho baixo é justamente devido à capacidade limitada dos modelos em capturar a relação entre as características e a variável alvo.     \n",
    "\n",
    "Entre os modelos avaliados, o que se sobressaiu foi o otimizado com ``ElasticNet``, alcançando um score R2 de 0,51. No entanto, é importante notar que o RMSE deste modelo, que foi de 2,32, acabou sendo superior ao do modelo Ridge, que registrou um RMSE de 2,24. Isso sugere que, apesar do ElasticNet ter apresentado um melhor coeficiente de determinação, o modelo Ridge conseguiu minimizar mais efetivamente o erro nas previsões.   \n",
    "\n",
    "Portanto, a escolha do modelo ideal pode depender do equilíbrio entre a explicação da variância (R2) e a minimização do erro (RMSE)."
   ],
   "id": "20939ac64ba51276"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
